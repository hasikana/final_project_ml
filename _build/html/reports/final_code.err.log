Traceback (most recent call last):
  File "C:\Users\DeLL\AppData\Roaming\Python\Python311\site-packages\jupyter_cache\executors\utils.py", line 58, in single_nb_execution
    executenb(
  File "C:\Users\DeLL\AppData\Roaming\Python\Python311\site-packages\nbclient\client.py", line 1314, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\DeLL\AppData\Roaming\Python\Python311\site-packages\jupyter_core\utils\__init__.py", line 165, in wrapped
    return loop.run_until_complete(inner)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Program Files\Python311\Lib\asyncio\base_events.py", line 653, in run_until_complete
    return future.result()
           ^^^^^^^^^^^^^^^
  File "C:\Users\DeLL\AppData\Roaming\Python\Python311\site-packages\nbclient\client.py", line 709, in async_execute
    await self.async_execute_cell(
  File "C:\Users\DeLL\AppData\Roaming\Python\Python311\site-packages\nbclient\client.py", line 1062, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "C:\Users\DeLL\AppData\Roaming\Python\Python311\site-packages\nbclient\client.py", line 918, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.linear_model import RidgeClassifier

# Define classifiers for Experiment 2
classifiers = {
    "RidgeClassifier": RidgeClassifier(random_state=42),
    "RandomForestClassifier": RandomForestClassifier(random_state=42),
    "XGBClassifier": XGBClassifier(use_label_encoder=False, eval_metric="logloss", random_state=42)
}

# Start MLFlow run for Experiment 2
with mlflow.start_run(run_name="Experiment 2 - Multiple Classifiers"):

    results = {}

    for name, clf in classifiers.items():
        # Create pipeline for each classifier
        pipeline = Pipeline(steps=[
            ('preprocessor', preprocessor),
            ('classifier', clf)
        ])

        # Perform cross-validation
        cv_results = cross_validate(
            pipeline, X, y,
            cv=cv_strategy,
            scoring=scoring_metrics,
            return_train_score=True
        )

        # Fit pipeline on entire dataset
        pipeline.fit(X, y)
        y_pred = pipeline.predict(X)

        # Confusion matrix
        tn, fp, fn, tp = confusion_matrix(y, y_pred).ravel()

        # Log results to MLFlow
        mlflow.log_param(f"{name}_model_type", name)
        mlflow.log_metric(f"{name}_mean_cv_f1", cv_results['test_f1_weighted'].mean())
        mlflow.log_metric(f"{name}_std_cv_f1", cv_results['test_f1_weighted'].std())
        mlflow.log_metric(f"{name}_train_f1", f1_score(y, y_pred, average='weighted'))
        mlflow.log_metric(f"{name}_TP", tp)
        mlflow.log_metric(f"{name}_TN", tn)
        mlflow.log_metric(f"{name}_FP", fp)
        mlflow.log_metric(f"{name}_FN", fn)

        # Log the trained model
        mlflow.sklearn.log_model(pipeline, f"{name}_model")

        # Collect results for display
        results[name] = {
            "mean_cv_f1": cv_results['test_f1_weighted'].mean(),
            "std_cv_f1": cv_results['test_f1_weighted'].std(),
            "confusion_matrix": [[tn, fp], [fn, tp]]
        }

# Display results for all classifiers
for model, metrics in results.items():
    print(f"\n{model} Results:")
    print(f"Mean CV F1 Score: {metrics['mean_cv_f1']:.4f}")
    print(f"Std Dev CV F1 Score: {metrics['std_cv_f1']:.4f}")
    print(f"Confusion Matrix: {metrics['confusion_matrix']}")

------------------

----- stdout -----
ðŸƒ View run Experiment 2 - Multiple Classifiers at: https://dagshub.com/nalgondahasika30/bank_auth.mlflow/#/experiments/0/runs/57e411369ed34c9aa651548dc507544f
ðŸ§ª View experiment at: https://dagshub.com/nalgondahasika30/bank_auth.mlflow/#/experiments/0
------------------

[1;31m---------------------------------------------------------------------------[0m
[1;31mNameError[0m                                 Traceback (most recent call last)
Cell [1;32mIn[5], line 20[0m
[0;32m     15[0m results [38;5;241m=[39m {}
[0;32m     17[0m [38;5;28;01mfor[39;00m name, clf [38;5;129;01min[39;00m classifiers[38;5;241m.[39mitems():
[0;32m     18[0m     [38;5;66;03m# Create pipeline for each classifier[39;00m
[0;32m     19[0m     pipeline [38;5;241m=[39m Pipeline(steps[38;5;241m=[39m[
[1;32m---> 20[0m         ([38;5;124m'[39m[38;5;124mpreprocessor[39m[38;5;124m'[39m, [43mpreprocessor[49m),
[0;32m     21[0m         ([38;5;124m'[39m[38;5;124mclassifier[39m[38;5;124m'[39m, clf)
[0;32m     22[0m     ])
[0;32m     24[0m     [38;5;66;03m# Perform cross-validation[39;00m
[0;32m     25[0m     cv_results [38;5;241m=[39m cross_validate(
[0;32m     26[0m         pipeline, X, y,
[0;32m     27[0m         cv[38;5;241m=[39mcv_strategy,
[0;32m     28[0m         scoring[38;5;241m=[39mscoring_metrics,
[0;32m     29[0m         return_train_score[38;5;241m=[39m[38;5;28;01mTrue[39;00m
[0;32m     30[0m     )

[1;31mNameError[0m: name 'preprocessor' is not defined

